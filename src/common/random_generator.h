/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */

/*!
 * Copyright (c) 2017 by Contributors
 * \file random_generator.h
 * \brief Parallel random number generator.
 */
#ifndef MXNET_COMMON_RANDOM_GENERATOR_H_
#define MXNET_COMMON_RANDOM_GENERATOR_H_

#include <mxnet/base.h>
#include <random>
#include <new>

#if MXNET_USE_CUDA
#include <curand_kernel.h>
#include "../common/cuda_utils.h"
#endif  // MXNET_USE_CUDA

namespace mxnet {
namespace common {
namespace random {

template<typename Device, typename DType MSHADOW_DEFAULT_DTYPE>
class RandGenerator;

template<typename DType>
class RandGenerator<cpu, DType> {
 public:
  using RandomBitGenerator = mshadow::PCGRandom64;
  // at least how many random numbers should be generated by one CPU thread.
  static const int kMinNumRandomPerThread;
  // store how many global random states for CPU.
  static const int kNumRandomStates;

  // implementation class for random number generator
  class Impl {
   public:
    typedef typename std::conditional<std::is_floating_point<DType>::value,
                                      DType, double>::type FType;

    explicit Impl(RandGenerator<cpu, DType> *gen, int state_idx)
        : engine_(gen->states_ + state_idx) {}

    Impl(const Impl &) = delete;
    Impl &operator=(const Impl &) = delete;

    MSHADOW_XINLINE int rand() { return engine_->operator()(); }

    MSHADOW_XINLINE FType uniform() {
      typedef typename std::conditional<std::is_integral<DType>::value,
        std::uniform_int_distribution<DType>,
        mshadow::uniform_real_distribution<FType, RandomBitGenerator>>::type GType;
      GType dist_uniform;
      return dist_uniform(*engine_);
    }

    MSHADOW_XINLINE FType normal() {
      return dist_normal(*engine_);
    }

   private:
    RandGenerator<cpu, DType>::RandomBitGenerator *engine_;
    // more efficient as normal_distribution keeps its state between calls.
    mshadow::normal_distribution<FType, RandomBitGenerator> dist_normal;
  };

  static void AllocState(RandGenerator<cpu, DType> *inst) {
    inst->states_ = new RandomBitGenerator[kNumRandomStates];
  }

  static void FreeState(RandGenerator<cpu, DType> *inst) {
    delete[] inst->states_;
  }

  MSHADOW_XINLINE void Seed(mshadow::Stream<cpu> *, uint32_t seed, uint32_t sequence_id_offset) {
    for (int i = 0; i < kNumRandomStates; ++i) {
      (states_ + i)->seed(seed, sequence_id_offset + i);
    }
  }

 private:
  RandomBitGenerator *states_;
};  // class RandGenerator<cpu, DType>

template<typename DType>
const int RandGenerator<cpu, DType>::kMinNumRandomPerThread = 64;

template<typename DType>
const int RandGenerator<cpu, DType>::kNumRandomStates = 1024;

#if MXNET_USE_CUDA

__device__ unsigned cu_rand(mshadow::PCGRandom32* state);

template<typename ResultType>
__device__ ResultType cu_uniform(mshadow::PCGRandom32* state);

template<typename ResultType>
__device__ ResultType cu_normal(mshadow::PCGRandom32* state);

#ifdef __CUDACC__

inline __device__ unsigned cu_rand(mshadow::PCGRandom32* state) {
  return static_cast<unsigned>((*state)());
}

template<>
inline __device__ float cu_uniform<float>(mshadow::PCGRandom32* state) {
  return mshadow::RandomBitsToFPNumber<uint32_t>::Convert((*state)());
}

template<>
inline __device__ double cu_uniform<double>(mshadow::PCGRandom32* state) {
  mshadow::PCGRandom32::result_type u1 = (*state)();
  mshadow::PCGRandom32::result_type u2 = (*state)();
  uint64_t u3 = static_cast<uint64_t>(u1) << 32 | u2;
  return mshadow::RandomBitsToFPNumber<uint64_t>::Convert(u3);
}

template<typename ResultType>
inline __device__ ResultType cu_normal(mshadow::PCGRandom32* state) {
  // Box-Muller method
  using FPType = ResultType;
  using CM = mshadow::cuda::CuMath<FPType>;
  const FPType two_pi = 6.283185307179586;
  FPType u1 = cu_uniform<FPType>(state);
  while (u1 == 0) {
    u1 = cu_uniform<FPType>(state);
  }
  const FPType u2 = cu_uniform<FPType>(state);
  const FPType v1 = CM::sqrt(-FPType(2) * CM::log(u1));
  const FPType v2 = two_pi * u2;
  return v1 * CM::cos(v2);
}

#endif  // __CUDACC__

template<typename DType>
class RandGenerator<gpu, DType> {
 public:
  // generates float and convert to half_t if DType is halt_t.
  using FType = typename std::conditional<sizeof(DType) <= 4, float, double>::type;
  // at least how many random numbers should be generated by one GPU thread.
  static const int kMinNumRandomPerThread;
  // store how many global random states for GPU.
  static const int kNumRandomStates;

  class Impl {
   public:
    Impl &operator=(const Impl &) = delete;
    Impl(const Impl &) = delete;

    // Copy state to local memory for efficiency.
    __device__ explicit Impl(RandGenerator<gpu, DType> *gen, int state_idx)
        : global_gen_(gen),
          global_state_idx_(state_idx),
          state_(*(gen->states_ + state_idx)) {}

    __device__ ~Impl() {
      // store the curand state back into global memory
      global_gen_->states_[global_state_idx_] = state_;
    }

    MSHADOW_FORCE_INLINE __device__ int rand() {
      return cu_rand(&state_);
    }

    MSHADOW_FORCE_INLINE __device__ FType uniform() {
      return cu_uniform<FType>(&state_);
    }

    MSHADOW_FORCE_INLINE __device__ FType normal() {
      return cu_normal<FType>(&state_);
    }

   private:
    RandGenerator<gpu, DType> *global_gen_;
    int global_state_idx_;
    mshadow::PCGRandom32 state_;
  };  // class RandGenerator<gpu, DType>::Impl

  static void AllocState(RandGenerator<gpu, DType> *inst) {
    CUDA_CALL(cudaMalloc(&inst->states_,
                         kNumRandomStates * sizeof(mshadow::PCGRandom32)));
  }

  static void FreeState(RandGenerator<gpu, DType> *inst) {
    CUDA_CALL(cudaFree(inst->states_));
  }

  void Seed(mshadow::Stream<gpu> *s, uint32_t seed, uint32_t sequence_id_offset);

 private:
  mshadow::PCGRandom32 *states_;
};  // class RandGenerator<gpu, DType>

/*
template<>
class RandGenerator<gpu, double> {
 public:
  class Impl {
   public:
    Impl &operator=(const Impl &) = delete;
    Impl(const Impl &) = delete;

    // Copy state to local memory for efficiency.
    __device__ explicit Impl(RandGenerator<gpu, double> *gen, int state_idx)
        : global_gen_(gen),
          global_state_idx_(state_idx),
          state_(*(gen->states_ + state_idx)) {}

    __device__ ~Impl() {
      // store the curand state back into global memory
      global_gen_->states_[global_state_idx_] = state_;
    }

    MSHADOW_FORCE_INLINE __device__ int rand() {
      return cu_rand(&state_);
    }

    MSHADOW_FORCE_INLINE __device__ double uniform() {
      return cu_uniform<double>(&state_);
    }

    MSHADOW_FORCE_INLINE __device__ double normal() {
      return cu_normal<double>(&state_);
    }

   private:
    RandGenerator<gpu, double> *global_gen_;
    int global_state_idx_;
    mshadow::PCGRandom32 state_;
  };  // class RandGenerator<gpu, double>::Impl

 private:
  mshadow::PCGRandom32 *states_;
};  // class RandGenerator<gpu, double>
*/

#endif  // MXNET_USE_CUDA

}  // namespace random
}  // namespace common
}  // namespace mxnet
#endif  // MXNET_COMMON_RANDOM_GENERATOR_H_
